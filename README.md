# FastAPI LangGraph Agent Template

A production-ready FastAPI template for building AI agent applications with LangGraph integration. This template provides a robust foundation for building scalable, secure, and maintainable AI agent services.

## ğŸŒŸ Features

- **Production-Ready Architecture**

  - FastAPI for high-performance async API endpoints
  - LangGraph integration for AI agent workflows
  - Langfuse for LLM observability and monitoring
  - Structured logging with environment-specific formatting
  - Rate limiting with configurable rules
  - PostgreSQL for data persistence
  - Docker and Docker Compose support
  - Prometheus metrics and Grafana dashboards for monitoring

- **Security**

  - JWT-based authentication
  - Session management
  - Input sanitization
  - CORS configuration
  - Rate limiting protection

- **Developer Experience**

  - Environment-specific configuration
  - Comprehensive logging system
  - Clear project structure
  - Type hints throughout
  - Easy local development setup

- **Model Evaluation Framework**
  - Automated metric-based evaluation of model outputs
  - Integration with Langfuse for trace analysis
  - Detailed JSON reports with success/failure metrics
  - Interactive command-line interface
  - Customizable evaluation metrics

## ğŸš€ Quick Start

### Prerequisites

- Python 3.13+
- PostgreSQL ([see Database setup](#database-setup))
- Docker and Docker Compose (optional)

### Environment Setup

1. Clone the repository:

```bash
git clone <repository-url>
cd <project-directory>
```

2. Create and activate a virtual environment:

```bash
uv sync
```

3. Copy the example environment file:

```bash
cp .env.example .env.[development|staging|production] # e.g. .env.development
```

4. Update the `.env` file with your configuration (see `.env.example` for reference)

### Database setup

1. Create a PostgreSQL database (e.g Supabase or local PostgreSQL)
2. Update the database connection settings in your `.env` file:

```bash
POSTGRES_HOST=db
POSTGRES_PORT=5432
POSTGRES_DB=cool_db
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
```

- You don't have to create the tables manually, the ORM will handle that for you.But if you faced any issues,please run the `schemas.sql` file to create the tables manually.

### Running the Application

#### Local Development

1. Install dependencies:

```bash
uv sync
```

2. Run the application:

```bash
make [dev|staging|production] # e.g. make dev
```

1. Go to Swagger UI:

```bash
http://localhost:8000/docs
```

#### Using Docker

1. Build and run with Docker Compose:

```bash
make docker-build-env ENV=[development|staging|production] # e.g. make docker-build-env ENV=development
make docker-run-env ENV=[development|staging|production] # e.g. make docker-run-env ENV=development
```

2. Access the monitoring stack:

```bash
# Prometheus metrics
http://localhost:9090

# Grafana dashboards
http://localhost:3000
Default credentials:
- Username: admin
- Password: admin
```

The Docker setup includes:

- FastAPI application
- PostgreSQL database
- Prometheus for metrics collection
- Grafana for metrics visualization
- Pre-configured dashboards for:
  - API performance metrics
  - Rate limiting statistics
  - Database performance
  - System resource usage

## ğŸ“Š Model Evaluation

The project includes a robust evaluation framework for measuring and tracking model performance over time. The evaluator automatically fetches traces from Langfuse, applies evaluation metrics, and generates detailed reports.

### Running Evaluations

You can run evaluations with different options using the provided Makefile commands:

```bash
# Interactive mode with step-by-step prompts
make eval [ENV=development|staging|production]

# Quick mode with default settings (no prompts)
make eval-quick [ENV=development|staging|production]

# Evaluation without report generation
make eval-no-report [ENV=development|staging|production]
```

### Evaluation Features

- **Interactive CLI**: User-friendly interface with colored output and progress bars
- **Flexible Configuration**: Set default values or customize at runtime
- **Detailed Reports**: JSON reports with comprehensive metrics including:
  - Overall success rate
  - Metric-specific performance
  - Duration and timing information
  - Trace-level success/failure details

### Customizing Metrics

Evaluation metrics are defined in `evals/metrics/prompts/` as markdown files:

1. Create a new markdown file (e.g., `my_metric.md`) in the prompts directory
2. Define the evaluation criteria and scoring logic
3. The evaluator will automatically discover and apply your new metric

### Viewing Reports

Reports are automatically generated in the `evals/reports/` directory with timestamps in the filename:

```
evals/reports/evaluation_report_YYYYMMDD_HHMMSS.json
```

Each report includes:

- High-level statistics (total trace count, success rate, etc.)
- Per-metric performance metrics
- Detailed trace-level information for debugging

## ğŸ”§ Configuration

The application uses a flexible configuration system with environment-specific settings:

- `.env.development`
-

## æ•°æ®åº“ä¸å¯†é’¥é…ç½®
åœ¨ä½ çš„ .env æ–‡ä»¶ä¸­æ›´æ–°æ‰€æœ‰å¿…è¦çš„é…ç½®ã€‚

1. æ•°æ®åº“é…ç½®
æ›´æ–°æ•°æ®åº“è¿æ¥è®¾ç½®:

ä½ ä¸éœ€è¦æ‰‹åŠ¨åˆ›å»ºè¡¨ï¼ŒORM ä¼šè‡ªåŠ¨å¤„ç†ã€‚å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ‰‹åŠ¨è¿è¡Œ schemas.sql æ–‡ä»¶æ¥åˆ›å»ºè¡¨ã€‚

2. Langfuse (å¯è§‚æµ‹æ€§)
æ·»åŠ ä½ çš„ Langfuse é¡¹ç›®å¯†é’¥ã€‚

ä½ å¯ä»¥ç™»å½•åˆ°ä½ çš„ LANGFUSE_HOST (ä¾‹å¦‚: https://us.cloud.langfuse.com/) æ¥æŸ¥çœ‹ Agent çš„è¿è¡Œè½¨è¿¹ã€‚

3. Cleanlab (æ•°æ®è´¨é‡) - æ–°å¢
æ·»åŠ ä½ çš„ Cleanlab Codex API å¯†é’¥å’Œé¡¹ç›® IDã€‚

### å¦‚ä½•è·å– CLEANLAB_CODEX_API_KEY:

1. ç™»å½•

2. å³ä¸Šè§’ç‚¹å‡»ä½ çš„å¤´åƒ â†’ Settings / Account / API Keys

3. æ‰¾åˆ° User-level API Keyï¼ˆå¿…é¡»æ˜¯ User API Keyï¼Œä¸æ˜¯ Project API Keyï¼‰

ç‚¹å‡» Generate New Keyï¼ˆæˆ–å¤åˆ¶å·²æœ‰çš„ keyï¼‰

4. å¡«å…¥ .env æ–‡ä»¶ã€‚

### å¦‚ä½•è·å– CLEANLAB_PROJECT_ID:

åœ¨ Codex å·¦è¾¹æ é€‰æ‹© Projects

æ‰¾åˆ°ä½ åˆ›å»ºçš„é¡¹ç›®ï¼ˆå¦‚æœè¿˜æ²¡åˆ›å»ºå°±ç‚¹å‡» Create Projectï¼‰

ç‚¹å‡»è¿›å…¥é¡¹ç›®ï¼Œé¡¹ç›® URL ä¼šæ˜¯è¿™æ ·ï¼šhttps://codex.cleanlab.ai/projects/abcd1234efg56789

è¿™é‡Œçš„ abcd1234efg56789 å°±æ˜¯ä½ çš„ CLEANLAB_PROJECT_IDã€‚

### èº«ä»½éªŒè¯ & LLM
å…³äºå¦‚ä½•è·å–å…¶ä»–å¯†é’¥ï¼ŒChatGPT è·å–æ•™ç¨‹ã€‚

## å¦‚ä½•ä½¿ç”¨ (API æŒ‡å—)
ä¸€ä»½å…³äºå¦‚ä½•ä½¿ç”¨ http://127.0.0.1:8000/docs Swagger UI çš„å¿«é€ŸæŒ‡å—ï¼š

1. æ³¨å†Œ: æ‰¾åˆ° POST /api/v1/auth/registerã€‚ç‚¹å‡» "Try it out"ï¼Œè¾“å…¥ä½ çš„ä¿¡æ¯ï¼Œç„¶åç‚¹å‡» "Execute"ã€‚ä»å“åº”ä½“ (response body) ä¸­å¤åˆ¶ access_tokenã€‚

2. æˆæƒ: ç‚¹å‡»é¡µé¢å³ä¸Šè§’çš„ç»¿è‰² "Authorize" æŒ‰é’®ï¼ˆé”å›¾æ ‡ï¼‰ã€‚åœ¨ value å­—æ®µä¸­è¾“å…¥ Bearer (æ³¨æ„ Bearer åé¢æœ‰ä¸ªç©ºæ ¼)ï¼Œç„¶åç²˜è´´ä½ å¤åˆ¶çš„ access_tokenã€‚ç‚¹å‡» "Authorize"ã€‚

3. ç™»å½• (å¯é€‰): å¦‚æœä½ å·²æœ‰è´¦æˆ·ï¼Œå¯ä»¥ä½¿ç”¨ POST /api/v1/auth/login ç™»å½•ã€‚

4. è·å– Session: æ‰¾åˆ° POST /api/v1/auth/sessionã€‚ç‚¹å‡» "Try it out" å’Œ "Execute"ã€‚ä»å“åº”ä½“ä¸­å¤åˆ¶æ–°çš„ access_tokenã€‚

5. å†æ¬¡æˆæƒ: å†æ¬¡ç‚¹å‡» "Authorize" æŒ‰é’®ï¼ˆé”å›¾æ ‡ï¼‰ã€‚ç”¨ä½ åˆšä» /session è·å¾—çš„æ–° access_token æ›¿æ¢æ—§çš„ token (ç¡®ä¿ä¹ŸåŒ…å« Bearer )ã€‚

6. èŠå¤©: ä½ ç°åœ¨å·²é€šè¿‡èº«ä»½éªŒè¯ã€‚å¯ä»¥ä½¿ç”¨èŠå¤©ç«¯ç‚¹ï¼š

POST /api/v1/chatbot/chat

POST /api/v1/chatbot/chat/stream

## å¦‚ä½•ä½¿ç”¨Langfuse
éœ€è¦è´¦å·ã€‚å»è¿™é‡Œhttps://us.cloud.langfuse.com/ å¦‚æœä½ çš„LANGFUSE_HOST=https://us.cloud.langfuse.com
